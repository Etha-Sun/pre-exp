{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/clip/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'device': 'cpu', 'torch': '2.2.0'}\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to /Users/sun/.torch/datasets/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [01:18<00:00, 127013.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /Users/sun/.torch/datasets/MNIST/raw/train-images-idx3-ubyte.gz to /Users/sun/.torch/datasets/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to /Users/sun/.torch/datasets/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 104851.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /Users/sun/.torch/datasets/MNIST/raw/train-labels-idx1-ubyte.gz to /Users/sun/.torch/datasets/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to /Users/sun/.torch/datasets/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:04<00:00, 371152.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /Users/sun/.torch/datasets/MNIST/raw/t10k-images-idx3-ubyte.gz to /Users/sun/.torch/datasets/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to /Users/sun/.torch/datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 13118.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /Users/sun/.torch/datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz to /Users/sun/.torch/datasets/MNIST/raw\n",
            "\n",
            "{'train': 60000, 'test': 10000}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Data loading\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "def get_dataloaders(batch_size=BATCH_SIZE):\n",
        "    tf = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        # Keep in [0,1] since we want direct pixel-coefficient interpretability\n",
        "    ])\n",
        "    train_ds = datasets.MNIST(root=os.path.join('~', '.torch', 'datasets'), train=True, download=True, transform=tf)\n",
        "    test_ds = datasets.MNIST(root=os.path.join('~', '.torch', 'datasets'), train=False, download=True, transform=tf)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=torch.cuda.is_available())\n",
        "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=torch.cuda.is_available())\n",
        "    return train_loader, test_loader\n",
        "\n",
        "train_loader, test_loader = get_dataloaders()\n",
        "len_train, len_test = len(train_loader.dataset), len(test_loader.dataset)\n",
        "print({'train': len_train, 'test': len_test})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ring (hole) feature computation utilities\n",
        "import collections\n",
        "\n",
        "def compute_ring_feature(img: torch.Tensor, threshold: float = 0.5) -> int:\n",
        "    \"\"\"\n",
        "    Given a grayscale MNIST image tensor of shape [1, 28, 28] in [0,1],\n",
        "    returns 1 if there exists at least one background (0) connected component\n",
        "    fully enclosed by foreground (1), else 0.\n",
        "    We threshold > threshold as foreground.\n",
        "    \"\"\"\n",
        "    assert img.ndim == 3 and img.shape[0] == 1, \"Expected [1,H,W]\"\n",
        "    h, w = img.shape[1], img.shape[2]\n",
        "    x = (img[0] > threshold).cpu().numpy().astype(np.uint8)  # 1 for foreground strokes\n",
        "\n",
        "    # Background mask (0 where foreground, 1 where background)\n",
        "    bg = (x == 0).astype(np.uint8)\n",
        "\n",
        "    # Flood-fill background from border to mark non-hole background\n",
        "    visited = np.zeros_like(bg, dtype=np.uint8)\n",
        "    dq = collections.deque()\n",
        "\n",
        "    # Push all border background pixels\n",
        "    for i in range(h):\n",
        "        if bg[i, 0] and not visited[i, 0]:\n",
        "            visited[i, 0] = 1\n",
        "            dq.append((i, 0))\n",
        "        if bg[i, w - 1] and not visited[i, w - 1]:\n",
        "            visited[i, w - 1] = 1\n",
        "            dq.append((i, w - 1))\n",
        "    for j in range(w):\n",
        "        if bg[0, j] and not visited[0, j]:\n",
        "            visited[0, j] = 1\n",
        "            dq.append((0, j))\n",
        "        if bg[h - 1, j] and not visited[h - 1, j]:\n",
        "            visited[h - 1, j] = 1\n",
        "            dq.append((h - 1, j))\n",
        "\n",
        "    # 4-connected BFS\n",
        "    OFFSETS = [(1,0), (-1,0), (0,1), (0,-1)]\n",
        "    while dq:\n",
        "        i, j = dq.popleft()\n",
        "        for di, dj in OFFSETS:\n",
        "            ni, nj = i + di, j + dj\n",
        "            if 0 <= ni < h and 0 <= nj < w and bg[ni, nj] and not visited[ni, nj]:\n",
        "                visited[ni, nj] = 1\n",
        "                dq.append((ni, nj))\n",
        "\n",
        "    # Any background pixel not visited is a hole pixel\n",
        "    holes = (bg == 1) & (visited == 0)\n",
        "    return int(holes.any())\n",
        "\n",
        "class RingMNIST(Dataset):\n",
        "    def __init__(self, base: datasets.MNIST, threshold: float = 0.5):\n",
        "        self.base = base\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.base)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        img, label = self.base[idx]  # img: [1,28,28] float in [0,1]\n",
        "        ring = compute_ring_feature(img, threshold=self.threshold)\n",
        "        # Flatten pixels and append ring feature as extra dimension\n",
        "        pixels = img.view(-1)\n",
        "        feat = torch.cat([pixels, torch.tensor([float(ring)], dtype=pixels.dtype)])\n",
        "        return feat, label, torch.tensor(ring, dtype=torch.float32)\n",
        "\n",
        "INPUT_DIM = 28 * 28 + 1\n",
        "NUM_CLASSES = 10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "Can't pickle local object 'get_ring_loaders.<locals>.collate'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m train_loader, test_loader\n\u001b[1;32m     25\u001b[0m train_loader, test_loader \u001b[38;5;241m=\u001b[39m get_ring_loaders()\n\u001b[0;32m---> 26\u001b[0m xb, yb, rb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_feats\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mtuple\u001b[39m(xb\u001b[38;5;241m.\u001b[39mshape), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_labels\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mtuple\u001b[39m(yb\u001b[38;5;241m.\u001b[39mshape), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_ring\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mtuple\u001b[39m(rb\u001b[38;5;241m.\u001b[39mshape)})\n",
            "File \u001b[0;32m/opt/anaconda3/envs/clip/lib/python3.9/site-packages/torch/utils/data/dataloader.py:439\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/clip/lib/python3.9/site-packages/torch/utils/data/dataloader.py:387\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/clip/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1040\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1033\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1040\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
            "File \u001b[0;32m/opt/anaconda3/envs/clip/lib/python3.9/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/clip/lib/python3.9/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/clip/lib/python3.9/multiprocessing/context.py:284\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_posix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/clip/lib/python3.9/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/clip/lib/python3.9/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/clip/lib/python3.9/multiprocessing/popen_spawn_posix.py:47\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, fp)\n\u001b[0;32m---> 47\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
            "File \u001b[0;32m/opt/anaconda3/envs/clip/lib/python3.9/multiprocessing/reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, file, protocol)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Can't pickle local object 'get_ring_loaders.<locals>.collate'"
          ]
        }
      ],
      "source": [
        "# Wrap loaders with RingMNIST and fix dataset path expansion\n",
        "from pathlib import Path\n",
        "\n",
        "DATA_ROOT = str(Path.home() / '.torch' / 'datasets')\n",
        "\n",
        "\n",
        "def get_ring_loaders(batch_size=BATCH_SIZE, threshold: float = 0.5):\n",
        "    tf = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "    base_train = datasets.MNIST(root=DATA_ROOT, train=True, download=True, transform=tf)\n",
        "    base_test = datasets.MNIST(root=DATA_ROOT, train=False, download=True, transform=tf)\n",
        "\n",
        "    ring_train = RingMNIST(base_train, threshold=threshold)\n",
        "    ring_test = RingMNIST(base_test, threshold=threshold)\n",
        "\n",
        "    def collate(batch):\n",
        "        feats, labels, rings = zip(*batch)\n",
        "        return torch.stack(feats), torch.tensor(labels, dtype=torch.long), torch.stack(rings)\n",
        "\n",
        "    train_loader = DataLoader(ring_train, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=torch.cuda.is_available(), collate_fn=collate)\n",
        "    test_loader = DataLoader(ring_test, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=torch.cuda.is_available(), collate_fn=collate)\n",
        "    return train_loader, test_loader\n",
        "\n",
        "train_loader, test_loader = get_ring_loaders()\n",
        "xb, yb, rb = next(iter(train_loader))\n",
        "print({'batch_feats': tuple(xb.shape), 'batch_labels': tuple(yb.shape), 'batch_ring': tuple(rb.shape)})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sanity-check ring feature distribution\n",
        "from collections import Counter\n",
        "\n",
        "sample_loader, _ = get_ring_loaders(batch_size=1024)\n",
        "ring_counts = Counter()\n",
        "num_batches = 10\n",
        "for i, (_, _, rb) in enumerate(sample_loader):\n",
        "    ring_counts.update(rb.int().tolist())\n",
        "    if i >= num_batches - 1:\n",
        "        break\n",
        "print({'ring_feature_counts_over_first_batches': dict(ring_counts)})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Models: linear softmax and 1-hidden-layer MLP\n",
        "class LinearSoftmax(nn.Module):\n",
        "    def __init__(self, in_dim: int, num_classes: int):\n",
        "        super().__init__()\n",
        "        self.W = nn.Linear(in_dim, num_classes, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.W(x)\n",
        "\n",
        "class OneHiddenMLP(nn.Module):\n",
        "    def __init__(self, in_dim: int, hidden_dim: int, num_classes: int):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(in_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = F.relu(self.fc1(x))\n",
        "        return self.fc2(h)\n",
        "\n",
        "# Regularization: encourage reliance on ring feature\n",
        "# For linear model, directly L2-boost the last input weight per class\n",
        "# For MLP, encourage first-layer weights on ring feature and possibly path strength\n",
        "\n",
        "def ring_weight_penalty_linear(model: LinearSoftmax, alpha: float = 1.0):\n",
        "    # last input is ring feature\n",
        "    W = model.W.weight  # [C, D]\n",
        "    ring_w = W[:, -1]   # [C]\n",
        "    return -alpha * torch.mean(ring_w.abs())  # negative to increase magnitude\n",
        "\n",
        "\n",
        "def ring_weight_penalty_mlp(model: OneHiddenMLP, beta: float = 1.0):\n",
        "    # Encourage large absolute weights from ring input into hidden units\n",
        "    W1 = model.fc1.weight  # [H, D]\n",
        "    ring_w1 = W1[:, -1]    # [H]\n",
        "    return -beta * torch.mean(ring_w1.abs())\n",
        "\n",
        "\n",
        "def train_model(model, train_loader, test_loader, epochs=3, lr=1e-2, ring_reg=0.0, model_type='linear'):\n",
        "    model = model.to(DEVICE)\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        total_correct = 0\n",
        "        total = 0\n",
        "        for xb, yb, rb in train_loader:\n",
        "            xb = xb.to(DEVICE)\n",
        "            yb = yb.to(DEVICE)\n",
        "            logits = model(xb)\n",
        "            loss = criterion(logits, yb)\n",
        "            if ring_reg > 0:\n",
        "                if model_type == 'linear':\n",
        "                    loss = loss + ring_reg * ring_weight_penalty_linear(model)\n",
        "                else:\n",
        "                    loss = loss + ring_reg * ring_weight_penalty_mlp(model)\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "            total_loss += float(loss) * xb.size(0)\n",
        "            total_correct += (logits.argmax(dim=1) == yb).sum().item()\n",
        "            total += xb.size(0)\n",
        "        train_loss = total_loss / total\n",
        "        train_acc = total_correct / total\n",
        "\n",
        "        # Eval\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        count = 0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb, rb in test_loader:\n",
        "                xb = xb.to(DEVICE)\n",
        "                yb = yb.to(DEVICE)\n",
        "                logits = model(xb)\n",
        "                correct += (logits.argmax(dim=1) == yb).sum().item()\n",
        "                count += xb.size(0)\n",
        "        test_acc = correct / count\n",
        "        print({'epoch': epoch, 'train_loss': round(train_loss,4), 'train_acc': round(train_acc,4), 'test_acc': round(test_acc,4)})\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train linear model with ring-boost regularization\n",
        "linear = LinearSoftmax(INPUT_DIM, NUM_CLASSES)\n",
        "linear = train_model(linear, train_loader, test_loader, epochs=5, lr=1e-3, ring_reg=1e-3, model_type='linear')\n",
        "\n",
        "# Extract explicit formula: logits = W x + b\n",
        "W_lin = linear.W.weight.detach().cpu().numpy()   # [10, 785]\n",
        "b_lin = linear.W.bias.detach().cpu().numpy()     # [10]\n",
        "ring_weights_lin = W_lin[:, -1]\n",
        "print({'ring_weight_per_class_linear': ring_weights_lin.round(4).tolist()})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train 1-hidden-layer MLP with ring-boost regularization\n",
        "mlp = OneHiddenMLP(INPUT_DIM, hidden_dim=64, num_classes=NUM_CLASSES)\n",
        "mlp = train_model(mlp, train_loader, test_loader, epochs=5, lr=1e-3, ring_reg=1e-3, model_type='mlp')\n",
        "\n",
        "# Extract path contribution of ring feature (approx): average |w1[:, -1]| and top contributors\n",
        "with torch.no_grad():\n",
        "    w1 = mlp.fc1.weight.detach().cpu()\n",
        "    w2 = mlp.fc2.weight.detach().cpu()\n",
        "ring_in_w = w1[:, -1].abs()\n",
        "print({'mean_abs_ring_to_hidden': float(ring_in_w.mean())})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reporting: formulas and visualizations\n",
        "import seaborn as sns\n",
        "\n",
        "# Linear model: class c logit = dot(W_c, pixels_with_ring) + b_c\n",
        "print('Linear softmax explicit form:')\n",
        "for c in range(NUM_CLASSES):\n",
        "    print(f\"class {c}: logit = b[{c}] + sum_i W[{c},i]*x[i] + W[{c},ring]*ring\")\n",
        "\n",
        "# Show ring weights\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.bar(np.arange(NUM_CLASSES), ring_weights_lin)\n",
        "plt.title('Linear: ring weight per class')\n",
        "plt.xlabel('class')\n",
        "plt.ylabel('weight on ring feature')\n",
        "plt.show()\n",
        "\n",
        "# Visualize pixel weights per class for linear model\n",
        "fig, axes = plt.subplots(2, 5, figsize=(12,5))\n",
        "for c, ax in enumerate(axes.flat):\n",
        "    ax.imshow(W_lin[c, :-1].reshape(28,28), cmap='coolwarm')\n",
        "    ax.set_title(f'class {c}')\n",
        "    ax.axis('off')\n",
        "plt.suptitle('Linear: pixel weights per class')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# For MLP, logits = W2 * ReLU(W1 * x) + b2\n",
        "print('MLP (1 hidden layer, ReLU) form: logits = W2 * ReLU(W1 * x) + b2')\n",
        "# Ring path strengths approximation: |w1[:, -1]| * ||w2|| per class\n",
        "ring_to_hidden = w1[:, -1].numpy()\n",
        "ring_path_strength = np.abs(ring_to_hidden)  # simple proxy\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.hist(ring_path_strength, bins=20)\n",
        "plt.title('MLP: |ring -> hidden| weight distribution')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "clip",
      "language": "python",
      "name": "clip"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
